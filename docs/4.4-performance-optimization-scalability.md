# 4.4 Performance Optimization and Scalability

## 개요

ZK 시스템의 프로덕션 배포를 위해서는 성능 최적화와 확장성 전략이 필수적입니다. 이 문서에서는 회로 최적화, 증명 가속화, 분산 증명 생성, 그리고 대규모 시스템 설계를 다룹니다.

## 성능 병목 분석

### ZK 시스템 성능 프로파일

```
┌─────────────────────────────────────────────────────────────────┐
│              ZK System Performance Profile                       │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  [Prover Time Distribution]                                     │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │ MSM (Multi-Scalar Multiplication)  ████████████  60%    │   │
│  │ NTT (Number Theoretic Transform)   ██████       25%    │   │
│  │ Polynomial Operations              ███          10%    │   │
│  │ Other                              █            5%     │   │
│  └─────────────────────────────────────────────────────────┘   │
│                                                                  │
│  [Memory Usage]                                                 │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │ Constraint System                  ████████████  50%    │   │
│  │ Witness                            ██████       25%    │   │
│  │ Proving Key                        ████         15%    │   │
│  │ Intermediate Values                ██           10%    │   │
│  └─────────────────────────────────────────────────────────┘   │
│                                                                  │
│  [Verification Time Distribution]                               │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │ Pairing Operations                 ████████████  70%    │   │
│  │ Scalar Multiplication              ████         20%    │   │
│  │ Hash / Other                       ██           10%    │   │
│  └─────────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────────┘
```

### 복잡도 분석

```typescript
// ZK 연산 복잡도
interface ComplexityAnalysis {
    operation: string;
    timeComplexity: string;
    spaceComplexity: string;
    parallelizable: boolean;
}

const complexityTable: ComplexityAnalysis[] = [
    {
        operation: "FFT/NTT",
        timeComplexity: "O(n log n)",
        spaceComplexity: "O(n)",
        parallelizable: true,
    },
    {
        operation: "MSM (Pippenger)",
        timeComplexity: "O(n / log n)",
        spaceComplexity: "O(n)",
        parallelizable: true,
    },
    {
        operation: "Polynomial Evaluation",
        timeComplexity: "O(n)",
        spaceComplexity: "O(1)",
        parallelizable: true,
    },
    {
        operation: "Witness Generation",
        timeComplexity: "O(n)",
        spaceComplexity: "O(n)",
        parallelizable: false, // 의존성 있음
    },
    {
        operation: "Pairing (Verification)",
        timeComplexity: "O(1)",
        spaceComplexity: "O(1)",
        parallelizable: false,
    },
];
```

---

## 회로 최적화

### 제약조건 최소화

```circom
// 비효율적인 회로
pragma circom 2.0.0;

// BAD: 불필요한 제약조건
template BadRangeCheck(n) {
    signal input value;
    signal bits[n];

    var sum = 0;
    for (var i = 0; i < n; i++) {
        bits[i] <-- (value >> i) & 1;
        bits[i] * (1 - bits[i]) === 0;  // n개의 제약
        sum += bits[i] * (1 << i);
    }
    sum === value;  // 1개의 제약
    // 총: n + 1 제약조건
}

// GOOD: 최적화된 범위 체크
template GoodRangeCheck(n) {
    signal input value;
    signal output bits[n];

    var sum = 0;
    for (var i = 0; i < n; i++) {
        bits[i] <-- (value >> i) & 1;
        bits[i] * (1 - bits[i]) === 0;
        sum += bits[i] * (1 << i);
    }
    sum === value;
    // 동일하지만, 출력으로 재사용 가능
}

// BEST: Lookup table 사용 (PLONK)
// 8비트 청크로 분해하여 lookup 횟수 최소화
template OptimalRangeCheck(n) {
    signal input value;
    signal chunks[n/8];  // 8비트 청크

    var sum = 0;
    for (var i = 0; i < n/8; i++) {
        chunks[i] <-- (value >> (i * 8)) & 0xFF;
        // Lookup: chunks[i]가 0-255 범위인지 확인
        // 1개의 lookup per chunk (n/8 lookups)
        sum += chunks[i] * (1 << (i * 8));
    }
    sum === value;
}
```

### 비선형 연산 최적화

```circom
// 나눗셈 최적화
template Division() {
    signal input numerator;
    signal input denominator;
    signal output quotient;
    signal output remainder;

    // BAD: 직접 나눗셈 (불가능)
    // quotient <-- numerator / denominator;

    // GOOD: Hint + 검증
    quotient <-- numerator \ denominator;  // 정수 나눗셈 hint
    remainder <-- numerator % denominator;

    // 검증: numerator = quotient * denominator + remainder
    numerator === quotient * denominator + remainder;

    // 추가 제약: 0 <= remainder < denominator
    // (별도의 범위 체크 회로 필요)
}

// 비교 연산 최적화
template LessThanOptimized(n) {
    signal input a;
    signal input b;
    signal output out;

    // 차이 계산
    signal diff;
    diff <== b - a;

    // diff의 부호 비트 확인
    component sign = Num2Bits(n + 1);
    sign.in <== diff + (1 << n);  // 오프셋 추가하여 음수 처리

    out <== 1 - sign.out[n];  // 최상위 비트가 0이면 a < b
}
```

### 해시 함수 선택

```circom
// 해시 함수별 제약조건 수 비교
/*
 * SHA256: ~25,000 constraints per hash
 * Keccak256: ~145,000 constraints per hash
 * Poseidon: ~300 constraints per hash
 * MiMC: ~700 constraints per hash
 * Pedersen: ~1,500 constraints per hash
 */

include "poseidon.circom";

// ZK-friendly 해시 사용
template EfficientMerkleTree(levels) {
    signal input leaf;
    signal input pathElements[levels];
    signal input pathIndices[levels];
    signal output root;

    component hashers[levels];
    signal hashes[levels + 1];
    hashes[0] <== leaf;

    for (var i = 0; i < levels; i++) {
        hashers[i] = Poseidon(2);  // 가장 효율적

        // 조건부 스왑 최적화
        var left = hashes[i] + pathIndices[i] * (pathElements[i] - hashes[i]);
        var right = pathElements[i] + pathIndices[i] * (hashes[i] - pathElements[i]);

        hashers[i].inputs[0] <== left;
        hashers[i].inputs[1] <== right;
        hashes[i + 1] <== hashers[i].out;
    }

    root <== hashes[levels];
}
```

### 배치 처리

```circom
// 단일 처리 vs 배치 처리
template SingleTransfer() {
    signal input senderSecret;
    signal input recipientPubKey;
    signal input amount;
    // ... 제약조건들
    // 총 ~5000 constraints
}

// 배치 처리 (오버헤드 공유)
template BatchTransfer(batchSize) {
    signal input senderSecrets[batchSize];
    signal input recipientPubKeys[batchSize];
    signal input amounts[batchSize];

    // 공통 설정 오버헤드: 1000 constraints
    // 각 전송: 4000 constraints
    // 총: 1000 + 4000 * batchSize

    // 배치 크기가 클수록 전송당 비용 감소
    // batchSize=10: 4100 constraints/transfer
    // batchSize=100: 4010 constraints/transfer
}
```

---

## GPU 가속

### CUDA 기반 MSM

```cpp
// CUDA MSM 구현 개념
#include <cuda_runtime.h>

// 타원 곡선 점 구조체
struct Point {
    uint256_t x;
    uint256_t y;
    uint256_t z;  // Jacobian coordinates
};

// GPU 커널: Pippenger MSM
__global__ void pippenger_msm_kernel(
    Point* result,
    const Point* bases,      // n개의 기저점
    const uint256_t* scalars, // n개의 스칼라
    int n,
    int window_bits
) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    // 각 스레드가 윈도우 하나 처리
    int window_idx = idx;
    int num_windows = 256 / window_bits;

    if (window_idx >= num_windows) return;

    // 버킷 초기화
    __shared__ Point buckets[256];  // 2^window_bits buckets

    for (int i = 0; i < n; i++) {
        // 스칼라의 해당 윈도우 추출
        int bucket_idx = extract_window(scalars[i], window_idx, window_bits);

        if (bucket_idx > 0) {
            // 버킷에 점 추가
            point_add(&buckets[bucket_idx], &bases[i]);
        }
    }

    // 버킷 집계
    Point window_result = identity();
    Point running_sum = identity();

    for (int j = (1 << window_bits) - 1; j > 0; j--) {
        point_add(&running_sum, &buckets[j]);
        point_add(&window_result, &running_sum);
    }

    // 결과 저장
    result[window_idx] = window_result;
}

// 호스트 함수
void gpu_msm(Point* result, const Point* bases, const uint256_t* scalars, int n) {
    Point *d_bases, *d_result;
    uint256_t* d_scalars;

    // GPU 메모리 할당
    cudaMalloc(&d_bases, n * sizeof(Point));
    cudaMalloc(&d_scalars, n * sizeof(uint256_t));
    cudaMalloc(&d_result, 32 * sizeof(Point));  // 윈도우 수

    // 데이터 복사
    cudaMemcpy(d_bases, bases, n * sizeof(Point), cudaMemcpyHostToDevice);
    cudaMemcpy(d_scalars, scalars, n * sizeof(uint256_t), cudaMemcpyHostToDevice);

    // 커널 실행
    int threads = 256;
    int blocks = (32 + threads - 1) / threads;
    pippenger_msm_kernel<<<blocks, threads>>>(d_result, d_bases, d_scalars, n, 8);

    // 결과 수집
    Point window_results[32];
    cudaMemcpy(window_results, d_result, 32 * sizeof(Point), cudaMemcpyDeviceToHost);

    // 윈도우 결합 (CPU)
    *result = combine_windows(window_results, 32, 8);

    cudaFree(d_bases);
    cudaFree(d_scalars);
    cudaFree(d_result);
}
```

### GPU 가속 라이브러리

```rust
// gnark-crypto GPU 가속 (예시)
use gnark_crypto::ecc::bn254::G1Affine;
use gnark_crypto::msm;

fn gpu_accelerated_msm() {
    let points: Vec<G1Affine> = generate_points(1_000_000);
    let scalars: Vec<Fr> = generate_scalars(1_000_000);

    // GPU MSM (자동 감지)
    let config = msm::Config {
        device: msm::Device::GPU,
        num_threads: 8,
        ..Default::default()
    };

    let result = msm::msm_g1(&points, &scalars, &config);

    println!("MSM result computed on GPU");
}
```

### FPGA 가속

```verilog
// FPGA MSM 모듈 (개념적 Verilog)
module msm_accelerator #(
    parameter N = 1024,           // 점의 개수
    parameter SCALAR_BITS = 256,
    parameter WINDOW_SIZE = 8
)(
    input  clk,
    input  rst,
    input  start,
    input  [SCALAR_BITS-1:0] scalars [N-1:0],
    input  [511:0] bases [N-1:0],  // (x, y) affine
    output [511:0] result,
    output done
);
    // 상태 머신
    localparam IDLE = 0, BUCKET = 1, AGGREGATE = 2, COMBINE = 3;
    reg [1:0] state;

    // 버킷 메모리
    reg [511:0] buckets [255:0];

    // Pippenger 알고리즘 구현
    always @(posedge clk or posedge rst) begin
        if (rst) begin
            state <= IDLE;
        end else begin
            case (state)
                IDLE: if (start) state <= BUCKET;
                BUCKET: begin
                    // 병렬 버킷 채우기
                    // 파이프라인 처리
                end
                AGGREGATE: begin
                    // 버킷 집계
                end
                COMBINE: begin
                    // 윈도우 결합
                    state <= IDLE;
                end
            endcase
        end
    end

    // 점 덧셈 모듈 인스턴스
    point_adder adder_inst (
        .clk(clk),
        .p1(p1),
        .p2(p2),
        .result(p_sum)
    );

endmodule
```

---

## 병렬 및 분산 증명

### Multi-threaded Proving

```rust
use rayon::prelude::*;
use std::sync::Arc;

// 병렬 witness 계산
fn parallel_witness_generation<F: Field>(
    circuit: &Circuit<F>,
    public_inputs: &[F],
) -> Vec<F> {
    let num_constraints = circuit.num_constraints();

    // 독립적인 제약조건을 병렬 처리
    let witness: Vec<F> = (0..num_constraints)
        .into_par_iter()
        .map(|i| {
            circuit.compute_witness_for_constraint(i, public_inputs)
        })
        .collect();

    witness
}

// 병렬 FFT
fn parallel_fft<F: Field>(coeffs: &mut [F], omega: F) {
    let n = coeffs.len();
    let log_n = n.trailing_zeros() as usize;

    // Cooley-Tukey with parallel butterfly
    for s in 0..log_n {
        let m = 1 << (s + 1);
        let w_m = omega.pow(&[(n / m) as u64]);

        coeffs.par_chunks_mut(m).for_each(|chunk| {
            let mut w = F::one();
            for k in 0..m/2 {
                let t = w * chunk[k + m/2];
                let u = chunk[k];
                chunk[k] = u + t;
                chunk[k + m/2] = u - t;
                w *= w_m;
            }
        });
    }
}

// 병렬 MSM
fn parallel_msm<G: Group>(
    bases: &[G::Affine],
    scalars: &[G::Scalar],
) -> G {
    let chunk_size = bases.len() / rayon::current_num_threads();

    bases.par_chunks(chunk_size)
        .zip(scalars.par_chunks(chunk_size))
        .map(|(base_chunk, scalar_chunk)| {
            // 각 청크에서 Pippenger MSM
            pippenger_msm(base_chunk, scalar_chunk)
        })
        .reduce(G::identity, |a, b| a + b)
}
```

### 분산 증명 시스템

```typescript
// 분산 프로버 아키텍처
interface DistributedProver {
    coordinator: ProverCoordinator;
    workers: ProverWorker[];
}

interface ProverCoordinator {
    // 작업 분배
    distributeWork(circuit: Circuit, witness: Witness): TaskAssignment[];
    // 부분 증명 수집
    collectPartialProofs(partials: PartialProof[]): void;
    // 최종 증명 조합
    assembleProof(): Proof;
}

interface ProverWorker {
    id: string;
    // 할당된 작업 처리
    processTask(task: ProverTask): PartialProof;
    // 상태 보고
    reportStatus(): WorkerStatus;
}

// 분산 증명 구현 (개념적)
class DistributedProverImpl implements DistributedProver {
    coordinator: ProverCoordinator;
    workers: ProverWorker[];

    async generateProof(
        circuit: Circuit,
        witness: Witness
    ): Promise<Proof> {
        // 1. 회로를 청크로 분할
        const chunks = this.partitionCircuit(circuit);

        // 2. 작업 분배
        const tasks = chunks.map((chunk, i) => ({
            chunkId: i,
            constraints: chunk,
            witnessSlice: witness.slice(chunk.startIdx, chunk.endIdx),
        }));

        // 3. 병렬 처리
        const partialProofs = await Promise.all(
            tasks.map((task, i) =>
                this.workers[i % this.workers.length].processTask(task)
            )
        );

        // 4. 증명 조합
        return this.coordinator.assembleProof(partialProofs);
    }

    private partitionCircuit(circuit: Circuit): CircuitChunk[] {
        // 의존성 분석을 통한 최적 분할
        const dependencyGraph = analyzeDependencies(circuit);
        return topologicalPartition(dependencyGraph, this.workers.length);
    }
}
```

### Proof Aggregation

```rust
// 재귀적 증명 집계
use ark_groth16::{Groth16, Proof};
use ark_bn254::Bn254;

struct ProofAggregator {
    aggregation_circuit: AggregationCircuit,
    pk: ProvingKey,
    vk: VerifyingKey,
}

impl ProofAggregator {
    // N개의 증명을 1개로 집계
    fn aggregate(&self, proofs: Vec<Proof<Bn254>>) -> Proof<Bn254> {
        // 집계 회로 witness 생성
        let witness = self.aggregation_circuit.create_witness(&proofs);

        // 집계 증명 생성
        Groth16::prove(&self.pk, self.aggregation_circuit.clone(), &witness)
    }
}

// 집계 회로
struct AggregationCircuit<const N: usize> {
    proofs: [Option<Proof<Bn254>>; N],
    public_inputs: [Option<Vec<Fr>>; N],
    vk: VerifyingKey<Bn254>,
}

impl<const N: usize> ConstraintSynthesizer<Fr> for AggregationCircuit<N> {
    fn generate_constraints(
        self,
        cs: ConstraintSystemRef<Fr>,
    ) -> Result<(), SynthesisError> {
        // 각 증명 검증
        for i in 0..N {
            // Groth16 검증 회로 (in-circuit)
            let is_valid = groth16_verify_gadget(
                cs.clone(),
                &self.vk,
                &self.proofs[i],
                &self.public_inputs[i],
            )?;

            // 모든 증명이 유효해야 함
            is_valid.enforce_equal(&Boolean::TRUE)?;
        }

        Ok(())
    }
}
```

---

## 메모리 최적화

### Streaming Prover

```rust
// 스트리밍 프로버: 메모리 제한 환경용
struct StreamingProver<F: Field> {
    chunk_size: usize,
    max_memory: usize,
}

impl<F: Field> StreamingProver<F> {
    fn prove_streaming(
        &self,
        circuit_stream: impl Iterator<Item = Constraint<F>>,
        witness_stream: impl Iterator<Item = F>,
    ) -> Proof<F> {
        let mut commitment_accumulator = CommitmentAccumulator::new();
        let mut buffer = Vec::with_capacity(self.chunk_size);

        // 청크 단위로 처리
        for (constraint, witness) in circuit_stream.zip(witness_stream) {
            buffer.push((constraint, witness));

            if buffer.len() >= self.chunk_size {
                // 청크 처리
                let partial = self.process_chunk(&buffer);
                commitment_accumulator.add(partial);
                buffer.clear();

                // 메모리 정리
                self.garbage_collect();
            }
        }

        // 남은 버퍼 처리
        if !buffer.is_empty() {
            let partial = self.process_chunk(&buffer);
            commitment_accumulator.add(partial);
        }

        // 최종 증명 생성
        commitment_accumulator.finalize()
    }

    fn process_chunk(&self, chunk: &[(Constraint<F>, F)]) -> PartialCommitment<F> {
        // FFT 및 MSM을 청크 내에서 수행
        // 결과를 누적기에 추가
        unimplemented!()
    }
}
```

### Memory-Mapped Files

```rust
use memmap2::{MmapMut, MmapOptions};
use std::fs::OpenOptions;

// 대용량 증명 키를 메모리 매핑으로 처리
struct MappedProvingKey {
    mmap: MmapMut,
    header: ProvingKeyHeader,
}

impl MappedProvingKey {
    fn open(path: &str) -> Result<Self, std::io::Error> {
        let file = OpenOptions::new()
            .read(true)
            .write(true)
            .open(path)?;

        let mmap = unsafe { MmapOptions::new().map_mut(&file)? };

        let header = Self::read_header(&mmap);

        Ok(Self { mmap, header })
    }

    // 필요한 부분만 메모리에 로드
    fn get_commitment_key(&self, index: usize) -> &[u8] {
        let offset = self.header.commitment_keys_offset + index * POINT_SIZE;
        &self.mmap[offset..offset + POINT_SIZE]
    }

    // 대량의 점들을 스트리밍 방식으로 접근
    fn iter_points(&self) -> impl Iterator<Item = Point> + '_ {
        let start = self.header.points_offset;
        let end = start + self.header.num_points * POINT_SIZE;

        self.mmap[start..end]
            .chunks(POINT_SIZE)
            .map(Point::from_bytes)
    }
}
```

---

## Verification 최적화

### Batch Verification

```solidity
// SPDX-License-Identifier: MIT
pragma solidity ^0.8.0;

/**
 * @title BatchVerifier
 * @notice 여러 증명을 배치로 검증하여 가스 절약
 */
contract BatchVerifier {
    // 단일 검증: ~300K gas
    // 배치 검증: ~300K + 50K * (n-1) gas (n개 증명)

    struct Proof {
        uint256[2] a;
        uint256[2][2] b;
        uint256[2] c;
    }

    /**
     * @notice 배치 검증
     * @dev 랜덤 선형 결합으로 검증 비용 절감
     */
    function batchVerify(
        Proof[] calldata proofs,
        uint256[][] calldata publicInputs,
        uint256[] calldata randomCoeffs
    ) external view returns (bool) {
        require(proofs.length == publicInputs.length, "Length mismatch");
        require(proofs.length == randomCoeffs.length, "Length mismatch");

        // 선형 결합된 페어링 검사
        // e(sum(r_i * A_i), B) = e(sum(r_i * C_i), delta) * e(sum(r_i * input_i), gamma)

        uint256[2] memory aggregatedA;
        uint256[2][2] memory aggregatedB;
        uint256[2] memory aggregatedC;
        uint256[2] memory aggregatedInput;

        for (uint256 i = 0; i < proofs.length; i++) {
            uint256 r = randomCoeffs[i];

            // A 집계
            (aggregatedA[0], aggregatedA[1]) = ecAdd(
                aggregatedA[0], aggregatedA[1],
                ecMul(proofs[i].a[0], proofs[i].a[1], r)
            );

            // C 집계
            (aggregatedC[0], aggregatedC[1]) = ecAdd(
                aggregatedC[0], aggregatedC[1],
                ecMul(proofs[i].c[0], proofs[i].c[1], r)
            );

            // 공개 입력 집계
            uint256[2] memory inputCommit = computeInputCommitment(publicInputs[i]);
            (aggregatedInput[0], aggregatedInput[1]) = ecAdd(
                aggregatedInput[0], aggregatedInput[1],
                ecMul(inputCommit[0], inputCommit[1], r)
            );
        }

        // 단일 페어링 검증
        return pairingCheck(aggregatedA, aggregatedB, aggregatedC, aggregatedInput);
    }

    function ecAdd(uint256 x1, uint256 y1, uint256 x2, uint256 y2)
        internal view returns (uint256, uint256)
    {
        uint256[4] memory input = [x1, y1, x2, y2];
        uint256[2] memory result;
        assembly {
            if iszero(staticcall(gas(), 6, input, 128, result, 64)) {
                revert(0, 0)
            }
        }
        return (result[0], result[1]);
    }

    function ecMul(uint256 x, uint256 y, uint256 s)
        internal view returns (uint256, uint256)
    {
        uint256[3] memory input = [x, y, s];
        uint256[2] memory result;
        assembly {
            if iszero(staticcall(gas(), 7, input, 96, result, 64)) {
                revert(0, 0)
            }
        }
        return (result[0], result[1]);
    }
}
```

### Verifier Gas 최적화

```solidity
// SPDX-License-Identifier: MIT
pragma solidity ^0.8.0;

/**
 * @title OptimizedVerifier
 * @notice 가스 최적화된 Groth16 검증자
 */
contract OptimizedVerifier {
    // Verification key (하드코딩으로 SLOAD 비용 제거)
    uint256 constant ALPHA_X = 0x...;
    uint256 constant ALPHA_Y = 0x...;
    uint256 constant BETA_X1 = 0x...;
    // ... 기타 상수들

    // 상수 IC 포인트 (공개 입력 수에 따라)
    uint256 constant IC0_X = 0x...;
    uint256 constant IC0_Y = 0x...;
    // ...

    /**
     * @notice 최적화된 검증
     * @dev 인라인 어셈블리로 가스 최소화
     */
    function verifyProof(
        uint256[8] calldata proof,
        uint256[2] calldata input
    ) external view returns (bool) {
        // 어셈블리로 직접 precompile 호출
        assembly {
            let memPtr := mload(0x40)

            // 1. vk_x = IC[0] + input[0]*IC[1] + input[1]*IC[2]
            // EC mul: input[0] * IC[1]
            mstore(memPtr, IC1_X)
            mstore(add(memPtr, 0x20), IC1_Y)
            mstore(add(memPtr, 0x40), calldataload(add(input.offset, 0x00)))

            if iszero(staticcall(gas(), 7, memPtr, 0x60, memPtr, 0x40)) {
                revert(0, 0)
            }

            // EC add: IC[0] + result
            mstore(add(memPtr, 0x40), IC0_X)
            mstore(add(memPtr, 0x60), IC0_Y)

            if iszero(staticcall(gas(), 6, memPtr, 0x80, add(memPtr, 0x80), 0x40)) {
                revert(0, 0)
            }

            // 2. Pairing check
            // e(A, B) = e(alpha, beta) * e(vk_x, gamma) * e(C, delta)
            // => e(-A, B) * e(alpha, beta) * e(vk_x, gamma) * e(C, delta) = 1

            let pairingInput := add(memPtr, 0xC0)

            // -A (negate y coordinate)
            mstore(pairingInput, calldataload(proof.offset))
            mstore(add(pairingInput, 0x20),
                sub(21888242871839275222246405745257275088696311157297823662689037894645226208583,
                    calldataload(add(proof.offset, 0x20))))

            // B
            mstore(add(pairingInput, 0x40), calldataload(add(proof.offset, 0x40)))
            mstore(add(pairingInput, 0x60), calldataload(add(proof.offset, 0x60)))
            mstore(add(pairingInput, 0x80), calldataload(add(proof.offset, 0x80)))
            mstore(add(pairingInput, 0xa0), calldataload(add(proof.offset, 0xa0)))

            // ... 나머지 페어링 입력

            // Pairing precompile 호출 (address 8)
            if iszero(staticcall(gas(), 8, pairingInput, 0x300, memPtr, 0x20)) {
                revert(0, 0)
            }

            // 결과 확인 (1이면 유효)
            if iszero(mload(memPtr)) {
                revert(0, 0)
            }
        }

        return true;
    }
}
```

---

## 확장성 아키텍처

### 프로버 클러스터

```yaml
# Kubernetes 프로버 클러스터 설정
apiVersion: apps/v1
kind: Deployment
metadata:
  name: zk-prover-cluster
spec:
  replicas: 10
  selector:
    matchLabels:
      app: zk-prover
  template:
    metadata:
      labels:
        app: zk-prover
    spec:
      containers:
      - name: prover
        image: zk-prover:latest
        resources:
          requests:
            memory: "32Gi"
            cpu: "8"
            nvidia.com/gpu: 1
          limits:
            memory: "64Gi"
            cpu: "16"
            nvidia.com/gpu: 1
        env:
        - name: PROVER_MODE
          value: "distributed"
        - name: COORDINATOR_URL
          value: "http://prover-coordinator:8080"
---
apiVersion: v1
kind: Service
metadata:
  name: prover-coordinator
spec:
  selector:
    app: prover-coordinator
  ports:
  - port: 8080
    targetPort: 8080
```

### 프로버 API

```typescript
// 분산 프로버 API
import express from "express";
import { Queue } from "bull";

const app = express();
const proofQueue = new Queue("proof-generation", {
    redis: { host: "redis", port: 6379 },
    defaultJobOptions: {
        attempts: 3,
        backoff: { type: "exponential", delay: 5000 },
    },
});

// 증명 요청 API
app.post("/api/prove", async (req, res) => {
    const { circuitId, publicInputs, witness } = req.body;

    // 작업 큐에 추가
    const job = await proofQueue.add("generate", {
        circuitId,
        publicInputs,
        witness,
        timestamp: Date.now(),
    });

    res.json({
        jobId: job.id,
        status: "queued",
        estimatedTime: await estimateProofTime(circuitId),
    });
});

// 증명 상태 조회
app.get("/api/proof/:jobId", async (req, res) => {
    const job = await proofQueue.getJob(req.params.jobId);

    if (!job) {
        return res.status(404).json({ error: "Job not found" });
    }

    const state = await job.getState();
    const progress = job.progress();

    res.json({
        jobId: job.id,
        state,
        progress,
        result: state === "completed" ? job.returnvalue : null,
    });
});

// 워커 프로세스
proofQueue.process("generate", async (job) => {
    const { circuitId, publicInputs, witness } = job.data;

    // 회로 로드
    const circuit = await loadCircuit(circuitId);

    // 증명 생성 (진행률 업데이트)
    const proof = await generateProof(circuit, witness, (progress) => {
        job.progress(progress);
    });

    return { proof, publicInputs };
});

// 추정 시간 계산
async function estimateProofTime(circuitId: string): Promise<number> {
    const circuit = await loadCircuit(circuitId);
    const constraints = circuit.numConstraints;

    // 경험적 공식: ~1ms per 100 constraints (GPU 기준)
    const baseTime = constraints / 100;

    // 현재 큐 대기 시간 추가
    const queueLength = await proofQueue.count();
    const avgProcessTime = 30000; // 30초 평균

    return baseTime + queueLength * avgProcessTime;
}
```

---

## 벤치마킹 및 모니터링

### 성능 측정 프레임워크

```rust
use std::time::{Duration, Instant};

#[derive(Debug, Default)]
struct ProverMetrics {
    witness_generation: Duration,
    fft_time: Duration,
    msm_time: Duration,
    polynomial_ops: Duration,
    total_time: Duration,
    memory_peak: usize,
    num_constraints: usize,
}

impl ProverMetrics {
    fn to_json(&self) -> String {
        serde_json::json!({
            "witness_generation_ms": self.witness_generation.as_millis(),
            "fft_time_ms": self.fft_time.as_millis(),
            "msm_time_ms": self.msm_time.as_millis(),
            "polynomial_ops_ms": self.polynomial_ops.as_millis(),
            "total_time_ms": self.total_time.as_millis(),
            "memory_peak_mb": self.memory_peak / 1_000_000,
            "num_constraints": self.num_constraints,
            "constraints_per_second": self.num_constraints as f64 / self.total_time.as_secs_f64(),
        }).to_string()
    }
}

// 계측된 프로버
struct InstrumentedProver<P: Prover> {
    inner: P,
    metrics: ProverMetrics,
}

impl<P: Prover> InstrumentedProver<P> {
    fn prove(&mut self, circuit: &Circuit, witness: &Witness) -> Proof {
        let total_start = Instant::now();

        // Witness 생성 측정
        let start = Instant::now();
        let full_witness = self.inner.compute_witness(circuit, witness);
        self.metrics.witness_generation = start.elapsed();

        // FFT 측정
        let start = Instant::now();
        let polys = self.inner.perform_fft(&full_witness);
        self.metrics.fft_time = start.elapsed();

        // MSM 측정
        let start = Instant::now();
        let commitments = self.inner.perform_msm(&polys);
        self.metrics.msm_time = start.elapsed();

        // 다항식 연산 측정
        let start = Instant::now();
        let proof = self.inner.finalize_proof(commitments);
        self.metrics.polynomial_ops = start.elapsed();

        self.metrics.total_time = total_start.elapsed();
        self.metrics.num_constraints = circuit.num_constraints();

        proof
    }
}
```

### Prometheus 메트릭

```typescript
import { Counter, Gauge, Histogram, Registry } from "prom-client";

const register = new Registry();

// 메트릭 정의
const proofGenerationDuration = new Histogram({
    name: "zk_proof_generation_duration_seconds",
    help: "Time to generate a proof",
    labelNames: ["circuit_type"],
    buckets: [0.1, 0.5, 1, 5, 10, 30, 60, 120, 300],
    registers: [register],
});

const proofVerificationDuration = new Histogram({
    name: "zk_proof_verification_duration_seconds",
    help: "Time to verify a proof",
    labelNames: ["circuit_type"],
    buckets: [0.001, 0.005, 0.01, 0.05, 0.1],
    registers: [register],
});

const constraintCount = new Gauge({
    name: "zk_circuit_constraints_total",
    help: "Number of constraints in circuit",
    labelNames: ["circuit_type"],
    registers: [register],
});

const proofsGeneratedTotal = new Counter({
    name: "zk_proofs_generated_total",
    help: "Total number of proofs generated",
    labelNames: ["circuit_type", "status"],
    registers: [register],
});

// 메트릭 수집 미들웨어
function measureProofGeneration(circuitType: string) {
    const endTimer = proofGenerationDuration.startTimer({ circuit_type: circuitType });

    return {
        success: () => {
            endTimer();
            proofsGeneratedTotal.inc({ circuit_type: circuitType, status: "success" });
        },
        failure: () => {
            endTimer();
            proofsGeneratedTotal.inc({ circuit_type: circuitType, status: "failure" });
        },
    };
}
```

---

## 요약

| 최적화 영역 | 기법 | 예상 개선 |
|------------|------|----------|
| **회로 최적화** | 제약조건 최소화, ZK-friendly 해시 | 2-10x 제약조건 감소 |
| **GPU 가속** | CUDA MSM/FFT | 10-50x 속도 향상 |
| **병렬화** | Multi-thread, 분산 증명 | 8-32x 처리량 증가 |
| **메모리** | 스트리밍, Memory-mapped | 대용량 회로 지원 |
| **검증** | 배치 검증, 인라인 어셈블리 | 50-80% 가스 절감 |
| **확장성** | 프로버 클러스터, 재귀 집계 | 무한 확장 가능 |

### 최적화 우선순위

```
1. 회로 설계 최적화 (가장 큰 영향)
   - ZK-friendly primitives 사용
   - 불필요한 제약조건 제거
   - Lookup tables 활용 (PLONK)

2. 알고리즘 최적화
   - Pippenger MSM
   - Cooley-Tukey FFT
   - 배치 처리

3. 하드웨어 가속
   - GPU (가성비 최고)
   - FPGA (특수 용도)
   - ASIC (대량 생산 시)

4. 시스템 아키텍처
   - 분산 증명
   - 증명 집계
   - 캐싱 전략
```

이로써 Stage 4 문서가 완료되었습니다.
