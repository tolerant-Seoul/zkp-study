/**
 * A queue that groups items into batches based on a group key.
 *
 * The batching algorithm is greedy, meaning that as long as consecutive items have the same group key then they will
 * be batched together. As soon as an item with a different group key is encountered, the old batch is flushed to the
 * queue and a new batch is started.
 *
 * A batch can also be flushed to the queue if:
 * - it reaches the selected batch size limit
 * - or the batch duration limit is hit (in milliseconds)
 *
 * This ensures that batches don't grow too big and that they are flushed at a minimum rate of 1 batch every interval.
 *
 * The consumer side of this queue will process batches as quickly as possible.
 */
export declare class BatchQueue<T, K extends string | number> {
    private processBatch;
    private maxBatchSize;
    private maxBatchDuration;
    private log;
    private container;
    private currentBatch?;
    private runningPromise?;
    constructor(processBatch: (items: Array<T>, key: K) => void | Promise<void>, maxBatchSize: number, maxBatchDuration: number, log?: import("../log/pino-logger.js").Logger);
    /**
     * Put an item in the queue. It will be routed based on the given key
     * @param item - The item to add
     * @param key - The group key for this item
     * @returns A promise that resolves or rejects when the batch this item is part of is processed
     */
    put(item: T, key: K): Promise<void>;
    /**
     * Immediately flushes the current batch, starting a new one
     */
    flushCurrentBatch: () => void;
    /**
     * Starts the queue.
     */
    start(): void;
    /**
     * Stops the queue. Any items in the queue will continue to be processed but new items won't be accepted anymore
     * @returns A promise that resolves when the queue is drained completely
     */
    stop(): Promise<void>;
    private execProcessor;
}
//# sourceMappingURL=batch_queue.d.ts.map